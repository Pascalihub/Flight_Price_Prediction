{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f712d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17c78d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5c4b8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\PASCAL\\\\flight_price_prediction\\\\research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1764255",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e55b491e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\PASCAL\\\\flight_price_prediction'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c701fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    preprocessor_path: Path    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9b1cf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.flightprice.constants import *\n",
    "from src.flightprice.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56b5cb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "            preprocessor_path = config.preprocessor_path\n",
    "        )\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65f3b341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from src.flightprice.utils.common import save_object'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from src.flightprice.logger import logging\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler,OrdinalEncoder\n",
    "import pickle\n",
    "'''from src.flightprice.utils.common import save_object'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11b20b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def parse_datetime_columns(self, df):\n",
    "        df[\"Date_of_Journey\"] = pd.to_datetime(df[\"Date_of_Journey\"], format=\"%d/%m/%Y\")\n",
    "        df[\"Journey_day\"] = df[\"Date_of_Journey\"].dt.day\n",
    "        df[\"Journey_month\"] = df[\"Date_of_Journey\"].dt.month\n",
    "        df.drop([\"Date_of_Journey\"], axis=1, inplace=True)\n",
    "\n",
    "        # Extracting Hours and Minutes for Departure and Arrival times\n",
    "        df[\"Dep_hour\"] = pd.to_datetime(df[\"Dep_Time\"]).dt.hour\n",
    "        df[\"Dep_min\"] = pd.to_datetime(df[\"Dep_Time\"]).dt.minute\n",
    "        df.drop([\"Dep_Time\"], axis=1, inplace=True)\n",
    "\n",
    "        df[\"Arrival_hour\"] = pd.to_datetime(df[\"Arrival_Time\"]).dt.hour\n",
    "        df[\"Arrival_min\"] = pd.to_datetime(df[\"Arrival_Time\"]).dt.minute\n",
    "        df.drop([\"Arrival_Time\"], axis=1, inplace=True)\n",
    "        df.drop([\"Route\", \"Additional_Info\"], axis = 1, inplace = True)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def parse_duration_column(self, df):\n",
    "        duration = list(df[\"Duration\"])\n",
    "\n",
    "        for i in range(len(duration)):\n",
    "            if len(duration[i].split()) != 2:  # Check if duration contains only hour or mins\n",
    "                if \"h\" in duration[i]:\n",
    "                    duration[i] = duration[i].strip() + \" 0m\"  # Adds 0 minute\n",
    "                else:\n",
    "                    duration[i] = \"0h \" + duration[i]  # Adds 0 hour\n",
    "\n",
    "        duration_hours = []\n",
    "        duration_mins = []\n",
    "        for i in range(len(duration)):\n",
    "            duration_hours.append(int(duration[i].split(sep=\"h\")[0]))  # Extract hours from duration\n",
    "            duration_mins.append(int(duration[i].split(sep=\"m\")[0].split()[-1]))  # Extracts only minutes from duration\n",
    "\n",
    "        # Adding duration_hours and duration_mins columns to the dataframe\n",
    "        df[\"Duration_hours\"] = duration_hours\n",
    "        df[\"Duration_mins\"] = duration_mins\n",
    "\n",
    "        # Drop the original \"Duration\" column\n",
    "        df.drop([\"Duration\"], axis=1, inplace=True)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def parse_Total_Stops(self, df):\n",
    "        df.replace({\"non-stop\": 0, \n",
    "                    \"1 stop\": 1, \n",
    "                    \"2 stops\": 2, \n",
    "                    \"3 stops\": 3, \n",
    "                    \"4 stops\": 4}, \n",
    "                    inplace = True)\n",
    "\n",
    "    def get_data_transformer_obj(self):\n",
    "        '''\n",
    "        This function is responsible for data transformation\n",
    "        '''\n",
    "        try:\n",
    "            # Define which columns should be ordinal-encoded and which should be scaled\n",
    "            numerical_columns=['Journey_day', 'Journey_month', \n",
    "                                 'Dep_hour', 'Dep_min', \n",
    "                                 'Arrival_hour', 'Arrival_min', \n",
    "                                 'Duration_hours', 'Duration_mins']\n",
    "            categorical_columns=[\n",
    "                'Airline', 'Source', 'Destination', 'Route', 'Total_Stops', 'Additional_Info'\n",
    "            ]\n",
    "            \n",
    "            # Define the custom ranking for each ordinal variable\n",
    "            Airline = tuple(['IndiGo', 'Air India', 'Jet Airways', 'SpiceJet', 'Multiple carriers', 'GoAir',\n",
    "            'Vistara', 'Air Asia', 'Vistara Premium economy', 'Jet Airways Business',\n",
    "            'Multiple carriers Premium economy', 'Trujet'])\n",
    "            Source = tuple(['Banglore', 'Kolkata', 'Delhi', 'Chennai', 'Mumbai'])\n",
    "            Destination = tuple(['Cochin', 'Banglore', 'Delhi', 'New Delhi', 'Hyderabad', 'Kolkata'])\n",
    "            Route = tuple(['BLR → DEL', 'CCU → IXR → BBI → BLR', 'DEL → LKO → BOM → COK',\n",
    "            'CCU → NAG → BLR', 'BLR → NAG → DEL', 'CCU → BLR', 'BLR → BOM → DEL',   \n",
    "            'DEL → BOM → COK', 'DEL → BLR → COK', 'MAA → CCU', 'CCU → BOM → BLR',\n",
    "            'DEL → AMD → BOM → COK', 'DEL → PNQ → COK', 'DEL → CCU → BOM → COK',\n",
    "            'BLR → COK → DEL', 'DEL → IDR → BOM → COK', 'DEL → LKO → COK',\n",
    "            'CCU → GAU → DEL → BLR', 'DEL → NAG → BOM → COK', 'CCU → MAA → BLR',\n",
    "            'DEL → HYD → COK', 'CCU → HYD → BLR', 'DEL → COK', 'CCU → DEL → BLR',\n",
    "            'BLR → BOM → AMD → DEL', 'BOM → DEL → HYD', 'DEL → MAA → COK', 'BOM → HYD',\n",
    "            'DEL → BHO → BOM → COK', 'DEL → JAI → BOM → COK', 'DEL → ATQ → BOM → COK',\n",
    "            'DEL → JDH → BOM → COK', 'CCU → BBI → BOM → BLR', 'BLR → MAA → DEL',\n",
    "            'DEL → GOI → BOM → COK', 'DEL → BDQ → BOM → COK', 'CCU → JAI → BOM → BLR',\n",
    "            'CCU → BBI → BLR', 'BLR → HYD → DEL', 'DEL → TRV → COK',\n",
    "            'CCU → IXR → DEL → BLR', 'DEL → IXU → BOM → COK', 'CCU → IXB → BLR',\n",
    "            'BLR → BOM → JDH → DEL', 'DEL → UDR → BOM → COK', 'DEL → HYD → MAA → COK',\n",
    "            'CCU → BOM → COK → BLR', 'BLR → CCU → DEL', 'CCU → BOM → GOI → BLR',\n",
    "            'DEL → RPR → NAG → BOM → COK', 'DEL → HYD → BOM → COK',\n",
    "            'CCU → DEL → AMD → BLR', 'CCU → PNQ → BLR', 'BLR → CCU → GAU → DEL',\n",
    "            'CCU → DEL → COK → BLR', 'BLR → PNQ → DEL', 'BOM → JDH → DEL → HYD',\n",
    "            'BLR → BOM → BHO → DEL', 'DEL → AMD → COK', 'BLR → LKO → DEL',\n",
    "            'CCU → GAU → BLR', 'BOM → GOI → HYD', 'CCU → BOM → AMD → BLR',\n",
    "            'CCU → BBI → IXR → DEL → BLR', 'DEL → DED → BOM → COK',\n",
    "            'DEL → MAA → BOM → COK', 'BLR → AMD → DEL', 'BLR → VGA → DEL',\n",
    "            'CCU → JAI → DEL → BLR', 'CCU → AMD → BLR', 'CCU → VNS → DEL → BLR',\n",
    "            'BLR → BOM → IDR → DEL', 'BLR → BBI → DEL', 'BLR → GOI → DEL',\n",
    "            'BOM → AMD → ISK → HYD', 'BOM → DED → DEL → HYD', 'DEL → IXC → BOM → COK',\n",
    "            'CCU → PAT → BLR', 'BLR → CCU → BBI → DEL', 'CCU → BBI → HYD → BLR',\n",
    "            'BLR → BOM → NAG → DEL', 'BLR → CCU → BBI → HYD → DEL', 'BLR → GAU → DEL',\n",
    "            'BOM → BHO → DEL → HYD', 'BOM → JLR → HYD', 'BLR → HYD → VGA → DEL',\n",
    "            'CCU → KNU → BLR', 'CCU → BOM → PNQ → BLR', 'DEL → BBI → COK',\n",
    "            'BLR → VGA → HYD → DEL', 'BOM → JDH → JAI → DEL → HYD',\n",
    "            'DEL → GWL → IDR → BOM → COK', 'CCU → RPR → HYD → BLR', 'CCU → VTZ → BLR',\n",
    "            'CCU → DEL → VGA → BLR', 'BLR → BOM → IDR → GWL → DEL',\n",
    "            'CCU → DEL → COK → TRV → BLR', 'BOM → COK → MAA → HYD', 'BOM → NDC → HYD',\n",
    "            'BLR → BDQ → DEL', 'CCU → BOM → TRV → BLR', 'CCU → BOM → HBX → BLR',\n",
    "            'BOM → BDQ → DEL → HYD', 'BOM → CCU → HYD', 'BLR → TRV → COK → DEL',\n",
    "            'BLR → IDR → DEL', 'CCU → IXZ → MAA → BLR', 'CCU → GAU → IMF → DEL → BLR',\n",
    "            'BOM → GOI → PNQ → HYD', 'BOM → BLR → CCU → BBI → HYD', 'BOM → MAA → HYD',\n",
    "            'BLR → BOM → UDR → DEL', 'BOM → UDR → DEL → HYD', 'BLR → VGA → VTZ → DEL',\n",
    "            'BLR → HBX → BOM → BHO → DEL', 'CCU → IXA → BLR', 'BOM → RPR → VTZ → HYD',\n",
    "            'BLR → HBX → BOM → AMD → DEL', 'BOM → IDR → DEL → HYD' ,'BOM → BLR → HYD',\n",
    "            'BLR → STV → DEL', 'CCU → IXB → DEL → BLR', 'BOM → JAI → DEL → HYD',\n",
    "            'BOM → VNS → DEL → HYD', 'BLR → HBX → BOM → NAG → DEL',\n",
    "            'BLR → BOM → IXC → DEL', 'BLR → CCU → BBI → HYD → VGA → DEL',\n",
    "            'BOM → BBI → HYD'])\n",
    "            Total_Stops = tuple(['non-stop', '2 stops', '1 stop', '3 stops', '4 stops'])\n",
    "            Additional_Info = tuple(['No info', 'In-flight meal not included', 'No check-in baggage included',\n",
    "            '1 Short layover', 'No Info', '1 Long layover', 'Change airports',\n",
    "            'Business class', 'Red-eye flight', '2 Long layover'])\n",
    "\n",
    "            # Numerical Pipeline\n",
    "            num_pipeline = Pipeline(\n",
    "                steps = [\n",
    "                ('imputer',SimpleImputer(strategy='median')),\n",
    "                ('scaler',StandardScaler())                \n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # Categorical Pipeline\n",
    "            cat_pipeline = Pipeline(\n",
    "                steps=[\n",
    "                ('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "                ('ordinal_encoder',OrdinalEncoder(categories=[Airline,\n",
    "                Source,\n",
    "                Destination,\n",
    "                Route,\n",
    "                Total_Stops,\n",
    "                Additional_Info])),\n",
    "                ('scaler',StandardScaler())\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            logging.info(f'Categorical Columns : {categorical_columns}')\n",
    "            logging.info(f'Numerical Columns   : {numerical_columns}')\n",
    "\n",
    "            preprocessor = ColumnTransformer(\n",
    "                [\n",
    "                ('num_pipeline',num_pipeline,numerical_columns),\n",
    "                ('cat_pipeline',cat_pipeline,categorical_columns)\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            return preprocessor\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in get_data_transformer_object: {str(e)}\")\n",
    "\n",
    "    def initiate_data_transformation(self):\n",
    "        try:\n",
    "            train_data_path = 'artifacts/data_ingestion/unzipped_data/train_data.csv'\n",
    "            test_data_path = 'artifacts/data_ingestion/unzipped_data/test_data.csv'\n",
    "\n",
    "            logging.info(\"Read train and test data completed\")\n",
    "\n",
    "            logging.info(\"Obtaining preprocessing object\")\n",
    "\n",
    "            # Read training and test data\n",
    "            train_df = pd.read_csv(train_data_path)\n",
    "            test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "            logging.info('Read train and test data completed')\n",
    "\n",
    "            logging.info(f'Train Dataframe Head : \\n{train_df.head().to_string()}')\n",
    "            logging.info(f'Test Dataframe Head  : \\n{test_df.head().to_string()}')\n",
    "            \n",
    "            logging.info('Obtaining preprocessing object')\n",
    "\n",
    "            preprocessing_obj = self.get_data_transformer_obj()\n",
    "\n",
    "            target_column_name = 'Price'\n",
    "\n",
    "            # Separate input features and target features\n",
    "            input_feature_train_df = train_df.drop(columns=[target_column_name], axis=1)\n",
    "            target_feature_train_df = train_df[target_column_name]\n",
    "\n",
    "            input_feature_test_df = test_df.drop(columns=[target_column_name], axis=1)\n",
    "            target_feature_test_df = test_df[target_column_name]\n",
    "\n",
    "            # Apply the preprocessing object on training and test input features\n",
    "            input_feature_train_arr=preprocessing_obj.fit_transform(input_feature_train_df)\n",
    "            input_feature_test_arr=preprocessing_obj.transform(input_feature_test_df)\n",
    "\n",
    "            # Combine input features and target features\n",
    "            train_arr = np.c_[\n",
    "                input_feature_train_arr, np.array(target_feature_train_df)\n",
    "            ]\n",
    "            \n",
    "            test_arr = np.c_[\n",
    "                input_feature_test_arr, np.array(target_feature_test_df)\n",
    "            ]\n",
    "\n",
    "            # Save preprocessing object\n",
    "            preprocessing_obj_file = os.path.join(\"artifacts\", 'data_transformation', 'preprocessing_obj.pkl')\n",
    "            with open(preprocessing_obj_file, 'wb') as file:\n",
    "                pickle.dump(preprocessing_obj, file)\n",
    "\n",
    "            logging.info(\"Saved preprocessing object.\")\n",
    "            logging.info(\"Transformation of the data is completed\")\n",
    "            \n",
    "            return (\n",
    "                train_arr,\n",
    "                test_arr,\n",
    "                preprocessing_obj_file\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in initiate_data_transformation: {str(e)}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c245e332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-27 04:11:05,769 - INFO - yaml file: config\\config.yaml loaded successfully\n",
      "2023-09-27 04:11:05,772 - INFO - yaml file: params.yaml loaded successfully\n",
      "2023-09-27 04:11:05,774 - INFO - created directory at: artifacts\n",
      "2023-09-27 04:11:05,775 - INFO - created directory at: artifacts/data_transformation\n",
      "2023-09-27 04:11:05,776 - INFO - Read train and test data completed\n",
      "2023-09-27 04:11:05,777 - INFO - Obtaining preprocessing object\n",
      "2023-09-27 04:11:05,935 - INFO - Read train and test data completed\n",
      "2023-09-27 04:11:05,946 - INFO - Train Dataframe Head : \n",
      "       Airline   Source Destination                        Route Total_Stops Additional_Info  Price  Journey_day  Journey_month  Dep_hour  Dep_min  Arrival_hour  Arrival_min  Duration_hours  Duration_mins\n",
      "0       IndiGo  Kolkata    Banglore                    CCU → BLR    non-stop         No info   4174           18              4        21       25             0            5               2             40\n",
      "1  Jet Airways    Delhi      Cochin              DEL → BOM → COK      1 stop         No info  14714           27              6         7        5            12           35               5             30\n",
      "2     Air Asia  Kolkata    Banglore              CCU → BBI → BLR      1 stop         No info   5162            9              5         6       50            10           30               3             40\n",
      "3    Air India    Delhi      Cochin  DEL → RPR → NAG → BOM → COK     3 stops         No info  10493           24              6         5       15             7           40              26             25\n",
      "4    Air India   Mumbai   Hyderabad        BOM → BHO → DEL → HYD     2 stops         No info  13904            6              3         6        0            19           25              37             25\n",
      "2023-09-27 04:11:05,956 - INFO - Test Dataframe Head  : \n",
      "             Airline   Source Destination                  Route Total_Stops              Additional_Info  Price  Journey_day  Journey_month  Dep_hour  Dep_min  Arrival_hour  Arrival_min  Duration_hours  Duration_mins\n",
      "0  Multiple carriers    Delhi      Cochin        DEL → BOM → COK      1 stop                      No info   7670           15              5         6        0            21            0              15              0\n",
      "1        Jet Airways  Kolkata    Banglore        CCU → DEL → BLR      1 stop                      No info  14151            1              5        20       25            22            5              25             40\n",
      "2             IndiGo   Mumbai   Hyderabad              BOM → HYD    non-stop                      No info   2754            1              5        19        5            20           35               1             30\n",
      "3        Jet Airways    Delhi      Cochin        DEL → BOM → COK      1 stop                      No info  14714            3              6         2       15            19            0              16             45\n",
      "4        Jet Airways    Delhi      Cochin  DEL → JDH → BOM → COK     2 stops  In-flight meal not included  15812           15              6        11       40            19            0               7             20\n",
      "2023-09-27 04:11:05,957 - INFO - Obtaining preprocessing object\n",
      "2023-09-27 04:11:05,958 - INFO - Categorical Columns : ['Airline', 'Source', 'Destination', 'Route', 'Total_Stops', 'Additional_Info']\n",
      "2023-09-27 04:11:05,959 - INFO - Numerical Columns   : ['Journey_day', 'Journey_month', 'Dep_hour', 'Dep_min', 'Arrival_hour', 'Arrival_min', 'Duration_hours', 'Duration_mins']\n",
      "2023-09-27 04:11:06,178 - INFO - Saved preprocessing object.\n",
      "2023-09-27 04:11:06,180 - INFO - Transformation of the data is completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 5.27629259e-01, -6.10142392e-01,  1.47850890e+00, ...,\n",
       "         -1.32704119e+00, -4.49184608e-01,  4.17400000e+03],\n",
       "        [ 1.58954303e+00,  1.10748901e+00, -9.53389937e-01, ...,\n",
       "          8.70209207e-01, -4.49184608e-01,  1.47140000e+04],\n",
       "        [-5.34284515e-01,  2.48673309e-01, -1.12709700e+00, ...,\n",
       "          8.70209207e-01, -4.49184608e-01,  5.16200000e+03],\n",
       "        ...,\n",
       "        [-1.24222703e+00, -1.46895809e+00, -2.16933936e+00, ...,\n",
       "         -1.32704119e+00, -4.49184608e-01,  6.14400000e+03],\n",
       "        [-1.80313257e-01,  2.48673309e-01, -6.05975818e-01, ...,\n",
       "          8.70209207e-01, -4.49184608e-01,  1.41510000e+04],\n",
       "        [ 1.58954303e+00, -1.46895809e+00, -1.82192524e+00, ...,\n",
       "          8.70209207e-01, -4.49184608e-01,  5.73300000e+03]]),\n",
       " array([[ 1.73658001e-01,  2.48673309e-01, -1.12709700e+00, ...,\n",
       "          8.70209207e-01, -4.49184608e-01,  7.67000000e+03],\n",
       "        [-1.47820787e+00,  2.48673309e-01,  1.30480184e+00, ...,\n",
       "          8.70209207e-01, -4.49184608e-01,  1.41510000e+04],\n",
       "        [-1.47820787e+00,  2.48673309e-01,  1.13109478e+00, ...,\n",
       "         -1.32704119e+00, -4.49184608e-01,  2.75400000e+03],\n",
       "        ...,\n",
       "        [-1.80313257e-01, -1.46895809e+00,  1.30480184e+00, ...,\n",
       "          8.70209207e-01,  1.25300262e+00,  1.10870000e+04],\n",
       "        [-1.80313257e-01,  1.10748901e+00, -2.58561698e-01, ...,\n",
       "          8.70209207e-01, -4.49184608e-01,  5.88300000e+03],\n",
       "        [-1.80313257e-01,  1.10748901e+00, -2.58561698e-01, ...,\n",
       "         -2.28415989e-01, -4.49184608e-01,  1.38820000e+04]]),\n",
       " 'artifacts\\\\data_transformation\\\\preprocessing_obj.pkl')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(data_transformation_config)\n",
    "    data_transformation.initiate_data_transformation()\n",
    "except Exception as e:\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c44e72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d50e31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

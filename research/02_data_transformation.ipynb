{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f712d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c4b8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\PASCAL\\\\flight_price_prediction\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1764255",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e55b491e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\PASCAL\\\\flight_price_prediction'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c701fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_train_path: Path\n",
    "    preprocessor_path: Path    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9b1cf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.flightprice.constants import *\n",
    "from src.flightprice.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56b5cb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    \n",
    "\n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "        root_dir=config.root_dir,\n",
    "        data_train_path=config.data_train_path,\n",
    "        preprocessor_path=config.preprocessor_path\n",
    "    )\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65f3b341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from src.flightprice.utils.common import save_object'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from src.flightprice.logger import logging\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "import pickle\n",
    "'''from src.flightprice.utils.common import save_object'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbce5b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config):\n",
    "        self.data_transformation_config = config\n",
    "\n",
    "    def get_data_transformer_object(self):\n",
    "        try:\n",
    "            data = pd.read_csv(self.data_transformation_config.data_train_path)\n",
    "\n",
    "            numerical_columns = [\"Dep_Time\", \"Arrival_Time\", \"Duration\"]\n",
    "            categorical_columns = [\n",
    "                'Airline', 'Source',\n",
    "                'Destination', 'Route',\n",
    "                'Total_Stops', 'Additional_Info'\n",
    "            ]\n",
    "\n",
    "            # Exclude non-numeric columns from the numerical columns list\n",
    "            numerical_columns = [col for col in numerical_columns if col in data.columns and data[col].dtype != object]\n",
    "\n",
    "            num_pipeline = Pipeline(\n",
    "                steps=[\n",
    "                    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                    (\"scaler\", StandardScaler())\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            cat_pipeline = Pipeline(\n",
    "                steps=[\n",
    "                    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                    (\"encoder\", OneHotEncoder())\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    (\"numeric\", num_pipeline, numerical_columns),\n",
    "                    (\"categorical\", cat_pipeline, categorical_columns)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            return preprocessor\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in get_data_transformer_object: {str(e)}\")\n",
    "\n",
    "    def initiate_data_transformation(self):\n",
    "        try:\n",
    "            data = pd.read_csv(self.data_transformation_config.data_train_path)\n",
    "\n",
    "            preprocessor = self.get_data_transformer_object()\n",
    "\n",
    "            target_column_name=\"Price\"\n",
    "            numerical_columns = [\"Dep_Time\", \"Arrival_Time\", \"Duration\"]\n",
    "\n",
    "            input_feature_train_df=data.drop(columns=[target_column_name],axis=1)\n",
    "            target_feature_train_df=data[target_column_name]\n",
    "\n",
    "            logging.info(\n",
    "                f\"Applying preprocessing object on training dataframe and testing dataframe.\")\n",
    "\n",
    "            transformed_data = preprocessor.fit_transform(input_feature_train_df)\n",
    "\n",
    "            output_dir = os.path.join(self.data_transformation_config.root_dir, \"artifacts/data_transformation\")\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            output_file = os.path.join(output_dir, \"preprocessors.pkl\")\n",
    "            with open(output_file, \"wb\") as file:\n",
    "                pickle.dump(preprocessor, file)\n",
    "\n",
    "            print(\"Data transformation completed and saved as a pickle file.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in initiate_data_transformation: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c245e332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-11 06:33:50,067: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2023-07-11 06:33:50,069: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-07-11 06:33:50,071: INFO: common: created directory at: artifacts]\n",
      "[2023-07-11 06:33:50,072: INFO: common: created directory at: artifacts/data_transformation]\n",
      "[2023-07-11 06:33:50,154: INFO: 1338166216: Applying preprocessing object on training dataframe and testing dataframe.]\n",
      "Data transformation completed and saved as a pickle file.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(data_transformation_config)\n",
    "    data_transformation.initiate_data_transformation()\n",
    "except Exception as e:\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f758434f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
